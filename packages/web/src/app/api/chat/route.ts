/**
 * POST /api/chat
 * 
 * Proxies chat messages to the OpenClaw gateway webchat.
 * Currently returns mock responses ‚Äî engine integration comes
 * when the gateway is actually running.
 * 
 * Request body:
 *   { message: string, sessionId?: string }
 * 
 * Response:
 *   { response: string, sessionId: string, timestamp: string }
 */

import { NextRequest, NextResponse } from 'next/server';

// Engine gateway WebSocket URL (configurable via env)
const ENGINE_WS_URL = process.env.ENGINE_WS_URL || 'ws://localhost:18789';
const ENGINE_CONNECTED = process.env.ENGINE_CONNECTED === 'true';

export interface ChatRequest {
  message: string;
  sessionId?: string;
}

export interface ChatResponse {
  response: string;
  sessionId: string;
  timestamp: string;
  source: 'engine' | 'mock';
}

export async function POST(request: NextRequest): Promise<NextResponse<ChatResponse | { error: string }>> {
  try {
    const body = await request.json() as ChatRequest;

    if (!body.message || typeof body.message !== 'string') {
      return NextResponse.json(
        { error: 'Missing or invalid "message" field' },
        { status: 400 }
      );
    }

    const message = body.message.trim();
    if (message.length === 0) {
      return NextResponse.json(
        { error: 'Message cannot be empty' },
        { status: 400 }
      );
    }

    if (message.length > 10000) {
      return NextResponse.json(
        { error: 'Message too long (max 10000 characters)' },
        { status: 400 }
      );
    }

    const sessionId = body.sessionId || generateSessionId();

    // TODO: When ENGINE_CONNECTED=true, proxy to actual gateway via WebSocket
    // For now, return a mock response
    if (ENGINE_CONNECTED) {
      try {
        const engineResponse = await proxyToEngine(message, sessionId);
        return NextResponse.json(engineResponse);
      } catch (err) {
        // Fall back to mock if engine is unreachable
        console.error('Engine proxy failed, falling back to mock:', err);
      }
    }

    // Mock response for development
    const response = generateMockResponse(message);
    
    return NextResponse.json({
      response,
      sessionId,
      timestamp: new Date().toISOString(),
      source: 'mock' as const,
    });

  } catch (err) {
    console.error('Chat API error:', err);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}

// Health check
export async function GET(): Promise<NextResponse> {
  return NextResponse.json({
    status: 'ok',
    engine: ENGINE_CONNECTED ? 'connected' : 'mock',
    engineUrl: ENGINE_WS_URL,
  });
}

/**
 * Proxy message to the OpenClaw gateway via HTTP.
 * Uses the gateway's webchat HTTP endpoint for simplicity.
 * WebSocket streaming will be added later.
 */
async function proxyToEngine(message: string, sessionId: string): Promise<ChatResponse> {
  // The gateway exposes an HTTP endpoint for webchat messages
  const httpUrl = ENGINE_WS_URL.replace('ws://', 'http://').replace('wss://', 'https://');
  
  const res = await fetch(`${httpUrl}/api/chat`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message, sessionId }),
    signal: AbortSignal.timeout(30000),
  });

  if (!res.ok) {
    throw new Error(`Engine responded with ${res.status}`);
  }

  const data = await res.json();
  return {
    response: data.response || data.content || 'No response from engine',
    sessionId,
    timestamp: new Date().toISOString(),
    source: 'engine',
  };
}

/**
 * Generate a contextual mock response for development/demo.
 */
function generateMockResponse(message: string): string {
  const lower = message.toLowerCase();

  if (lower.includes('rfi')) {
    return `üìã **RFI Query**\n\nI'd normally query Procore for your RFI data. Here's what I'll do once connected:\n\n‚Ä¢ Search open RFIs across your active projects\n‚Ä¢ Filter by status, assignee, or age\n‚Ä¢ Flag any overdue items (>7 days)\n\n‚ö†Ô∏è Engine not connected yet ‚Äî this is a preview response.`;
  }

  if (lower.includes('budget') || lower.includes('cost')) {
    return `üí∞ **Budget Analysis**\n\nOnce connected to your PMIS, I can:\n\n‚Ä¢ Show real-time cost code breakdowns\n‚Ä¢ Flag overruns (>5% threshold)\n‚Ä¢ Compare committed vs actual costs\n‚Ä¢ Track change order impact\n\n‚ö†Ô∏è Engine not connected yet ‚Äî this is a preview response.`;
  }

  if (lower.includes('schedule') || lower.includes('milestone') || lower.includes('delay')) {
    return `üìÖ **Schedule Check**\n\nWith P6/Procore access, I'll:\n\n‚Ä¢ Show critical path activities\n‚Ä¢ Flag upcoming milestones (14-day window)\n‚Ä¢ Detect float erosion\n‚Ä¢ Track delay impacts\n\n‚ö†Ô∏è Engine not connected yet ‚Äî this is a preview response.`;
  }

  if (lower.includes('submittal')) {
    return `üìë **Submittal Tracking**\n\nOnce connected, I can:\n\n‚Ä¢ List open/late submittals\n‚Ä¢ Track review status\n‚Ä¢ Flag items past their required date\n‚Ä¢ Create new submittal entries\n\n‚ö†Ô∏è Engine not connected yet ‚Äî this is a preview response.`;
  }

  if (lower.includes('hello') || lower.includes('hi') || lower.includes('hey')) {
    return `Hey! üëã I'm your BuildAI assistant ‚Äî ready to help with your construction projects.\n\nTry asking about:\n‚Ä¢ Open RFIs\n‚Ä¢ Budget status\n‚Ä¢ Schedule milestones\n‚Ä¢ Submittal tracking\n\n‚ö†Ô∏è Running in preview mode ‚Äî engine integration coming soon.`;
  }

  return `I received: "${message}"\n\nI'm your construction PM assistant. Once the engine is connected, I'll be able to:\n\n‚Ä¢ Query Procore, Unifier, P6\n‚Ä¢ Search project documents\n‚Ä¢ Run database queries\n‚Ä¢ Generate reports\n\n‚ö†Ô∏è Engine not connected yet ‚Äî this is a preview response.`;
}

function generateSessionId(): string {
  return `session-${Date.now()}-${Math.random().toString(36).substring(2, 8)}`;
}
